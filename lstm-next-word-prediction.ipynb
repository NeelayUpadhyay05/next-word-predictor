{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc2850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b847a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 9566\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/Sherlock_Holmes.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = [line for line in f.read().splitlines() if line.strip()]\n",
    "\n",
    "print(f\"Total sentences: {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19b63ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8421\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text.lower()).split()\n",
    "\n",
    "word_counts = Counter()\n",
    "for sentence in corpus:\n",
    "    word_counts.update(tokenize(sentence))\n",
    "\n",
    "# Build word index starting at 1 (0 = padding), sorted by frequency\n",
    "word_index = {word: idx + 1 for idx, (word, _) in enumerate(word_counts.most_common())}\n",
    "index_word = {idx: word for word, idx in word_index.items()}\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0d9819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input sequences: 94956\n"
     ]
    }
   ],
   "source": [
    "def texts_to_sequences(sentence, word_index):\n",
    "    return [word_index[w] for w in tokenize(sentence) if w in word_index]\n",
    "\n",
    "input_sequences = []\n",
    "for sentence in corpus:\n",
    "    tokenized = texts_to_sequences(sentence, word_index)\n",
    "    for i in range(1, len(tokenized)):\n",
    "        input_sequences.append(tokenized[:i + 1])\n",
    "\n",
    "print(f\"Total input sequences: {len(input_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b27f6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (94956, 17), y shape: (94956,)\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(seq) for seq in input_sequences)\n",
    "\n",
    "def pad_sequences_pre(sequences, max_len):\n",
    "    padded = np.zeros((len(sequences), max_len), dtype=np.int64)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        padded[i, max_len - len(seq):] = seq\n",
    "    return padded\n",
    "\n",
    "padded = pad_sequences_pre(input_sequences, max_len)\n",
    "\n",
    "X = padded[:, :-1]   # features\n",
    "y = padded[:, -1]    # labels as class indices (NOT one-hot)\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d250504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU name: NVIDIA GeForce RTX 5060 Laptop GPU\n",
      "Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6260c6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches per epoch: 1484\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = TextDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Total batches per epoch: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e99e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextLSTM(\n",
      "  (embedding): Embedding(8421, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 150, batch_first=True)\n",
      "  (fc): Linear(in_features=150, out_features=8421, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class TextLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=100, hidden_dim=150):\n",
    "        super(TextLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)       # (batch, seq_len, embed_dim)\n",
    "        out, _ = self.lstm(x)       # (batch, seq_len, hidden_dim)\n",
    "        out = out[:, -1, :]         # last timestep → (batch, hidden_dim)\n",
    "        return self.fc(out)         # (batch, vocab_size) — raw logits\n",
    "\n",
    "model = TextLSTM(vocab_size).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f374c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100 — Loss: 6.1479 — Accuracy: 0.0960\n",
      "Epoch   2/100 — Loss: 5.3496 — Accuracy: 0.1322\n",
      "Epoch   3/100 — Loss: 4.9369 — Accuracy: 0.1505\n",
      "Epoch   4/100 — Loss: 4.5780 — Accuracy: 0.1699\n",
      "Epoch   5/100 — Loss: 4.2522 — Accuracy: 0.1906\n",
      "Epoch   6/100 — Loss: 3.9505 — Accuracy: 0.2184\n",
      "Epoch   7/100 — Loss: 3.6727 — Accuracy: 0.2501\n",
      "Epoch   8/100 — Loss: 3.4171 — Accuracy: 0.2866\n",
      "Epoch   9/100 — Loss: 3.1833 — Accuracy: 0.3228\n",
      "Epoch  10/100 — Loss: 2.9685 — Accuracy: 0.3589\n",
      "Epoch  11/100 — Loss: 2.7721 — Accuracy: 0.3981\n",
      "Epoch  12/100 — Loss: 2.5906 — Accuracy: 0.4323\n",
      "Epoch  13/100 — Loss: 2.4233 — Accuracy: 0.4653\n",
      "Epoch  14/100 — Loss: 2.2725 — Accuracy: 0.4983\n",
      "Epoch  15/100 — Loss: 2.1301 — Accuracy: 0.5284\n",
      "Epoch  16/100 — Loss: 2.0003 — Accuracy: 0.5567\n",
      "Epoch  17/100 — Loss: 1.8806 — Accuracy: 0.5829\n",
      "Epoch  18/100 — Loss: 1.7711 — Accuracy: 0.6059\n",
      "Epoch  19/100 — Loss: 1.6708 — Accuracy: 0.6289\n",
      "Epoch  20/100 — Loss: 1.5775 — Accuracy: 0.6507\n",
      "Epoch  21/100 — Loss: 1.4917 — Accuracy: 0.6705\n",
      "Epoch  22/100 — Loss: 1.4138 — Accuracy: 0.6873\n",
      "Epoch  23/100 — Loss: 1.3409 — Accuracy: 0.7032\n",
      "Epoch  24/100 — Loss: 1.2725 — Accuracy: 0.7193\n",
      "Epoch  25/100 — Loss: 1.2126 — Accuracy: 0.7312\n",
      "Epoch  26/100 — Loss: 1.1556 — Accuracy: 0.7456\n",
      "Epoch  27/100 — Loss: 1.1023 — Accuracy: 0.7580\n",
      "Epoch  28/100 — Loss: 1.0530 — Accuracy: 0.7686\n",
      "Epoch  29/100 — Loss: 1.0087 — Accuracy: 0.7783\n",
      "Epoch  30/100 — Loss: 0.9683 — Accuracy: 0.7882\n",
      "Epoch  31/100 — Loss: 0.9303 — Accuracy: 0.7973\n",
      "Epoch  32/100 — Loss: 0.8953 — Accuracy: 0.8041\n",
      "Epoch  33/100 — Loss: 0.8607 — Accuracy: 0.8110\n",
      "Epoch  34/100 — Loss: 0.8320 — Accuracy: 0.8178\n",
      "Epoch  35/100 — Loss: 0.8034 — Accuracy: 0.8242\n",
      "Epoch  36/100 — Loss: 0.7790 — Accuracy: 0.8275\n",
      "Epoch  37/100 — Loss: 0.7539 — Accuracy: 0.8347\n",
      "Epoch  38/100 — Loss: 0.7328 — Accuracy: 0.8387\n",
      "Epoch  39/100 — Loss: 0.7108 — Accuracy: 0.8439\n",
      "Epoch  40/100 — Loss: 0.6927 — Accuracy: 0.8467\n",
      "Epoch  41/100 — Loss: 0.6769 — Accuracy: 0.8498\n",
      "Epoch  42/100 — Loss: 0.6575 — Accuracy: 0.8541\n",
      "Epoch  43/100 — Loss: 0.6441 — Accuracy: 0.8559\n",
      "Epoch  44/100 — Loss: 0.6291 — Accuracy: 0.8597\n",
      "Epoch  45/100 — Loss: 0.6158 — Accuracy: 0.8617\n",
      "Epoch  46/100 — Loss: 0.6038 — Accuracy: 0.8635\n",
      "Epoch  47/100 — Loss: 0.5944 — Accuracy: 0.8650\n",
      "Epoch  48/100 — Loss: 0.5812 — Accuracy: 0.8684\n",
      "Epoch  49/100 — Loss: 0.5730 — Accuracy: 0.8698\n",
      "Epoch  50/100 — Loss: 0.5632 — Accuracy: 0.8721\n",
      "Epoch  51/100 — Loss: 0.5547 — Accuracy: 0.8726\n",
      "Epoch  52/100 — Loss: 0.5461 — Accuracy: 0.8744\n",
      "Epoch  53/100 — Loss: 0.5408 — Accuracy: 0.8751\n",
      "Epoch  54/100 — Loss: 0.5320 — Accuracy: 0.8770\n",
      "Epoch  55/100 — Loss: 0.5271 — Accuracy: 0.8777\n",
      "Epoch  56/100 — Loss: 0.5211 — Accuracy: 0.8776\n",
      "Epoch  57/100 — Loss: 0.5146 — Accuracy: 0.8797\n",
      "Epoch  58/100 — Loss: 0.5081 — Accuracy: 0.8810\n",
      "Epoch  59/100 — Loss: 0.5061 — Accuracy: 0.8797\n",
      "Epoch  60/100 — Loss: 0.5015 — Accuracy: 0.8806\n",
      "Epoch  61/100 — Loss: 0.4946 — Accuracy: 0.8828\n",
      "Epoch  62/100 — Loss: 0.4932 — Accuracy: 0.8820\n",
      "Epoch  63/100 — Loss: 0.4862 — Accuracy: 0.8838\n",
      "Epoch  64/100 — Loss: 0.4866 — Accuracy: 0.8824\n",
      "Epoch  65/100 — Loss: 0.4817 — Accuracy: 0.8841\n",
      "Epoch  66/100 — Loss: 0.4760 — Accuracy: 0.8851\n",
      "Epoch  67/100 — Loss: 0.4792 — Accuracy: 0.8845\n",
      "Epoch  68/100 — Loss: 0.4730 — Accuracy: 0.8856\n",
      "Epoch  69/100 — Loss: 0.4678 — Accuracy: 0.8863\n",
      "Epoch  70/100 — Loss: 0.4683 — Accuracy: 0.8857\n",
      "Epoch  71/100 — Loss: 0.4683 — Accuracy: 0.8851\n",
      "Epoch  72/100 — Loss: 0.4631 — Accuracy: 0.8858\n",
      "Epoch  73/100 — Loss: 0.4574 — Accuracy: 0.8873\n",
      "Epoch  74/100 — Loss: 0.4642 — Accuracy: 0.8853\n",
      "Epoch  75/100 — Loss: 0.4529 — Accuracy: 0.8877\n",
      "Epoch  76/100 — Loss: 0.4569 — Accuracy: 0.8861\n",
      "Epoch  77/100 — Loss: 0.4515 — Accuracy: 0.8871\n",
      "Epoch  78/100 — Loss: 0.4518 — Accuracy: 0.8871\n",
      "Epoch  79/100 — Loss: 0.4530 — Accuracy: 0.8863\n",
      "Epoch  80/100 — Loss: 0.4459 — Accuracy: 0.8874\n",
      "Epoch  81/100 — Loss: 0.4466 — Accuracy: 0.8876\n",
      "Epoch  82/100 — Loss: 0.4492 — Accuracy: 0.8866\n",
      "Epoch  83/100 — Loss: 0.4399 — Accuracy: 0.8882\n",
      "Epoch  84/100 — Loss: 0.4440 — Accuracy: 0.8873\n",
      "Epoch  85/100 — Loss: 0.4446 — Accuracy: 0.8861\n",
      "Epoch  86/100 — Loss: 0.4436 — Accuracy: 0.8867\n",
      "Epoch  87/100 — Loss: 0.4350 — Accuracy: 0.8894\n",
      "Epoch  88/100 — Loss: 0.4384 — Accuracy: 0.8871\n",
      "Epoch  89/100 — Loss: 0.4362 — Accuracy: 0.8883\n",
      "Epoch  90/100 — Loss: 0.4343 — Accuracy: 0.8883\n",
      "Epoch  91/100 — Loss: 0.4351 — Accuracy: 0.8879\n",
      "Epoch  92/100 — Loss: 0.4400 — Accuracy: 0.8859\n",
      "Epoch  93/100 — Loss: 0.4323 — Accuracy: 0.8886\n",
      "Epoch  94/100 — Loss: 0.4267 — Accuracy: 0.8898\n",
      "Epoch  95/100 — Loss: 0.4310 — Accuracy: 0.8884\n",
      "Epoch  96/100 — Loss: 0.4382 — Accuracy: 0.8863\n",
      "Epoch  97/100 — Loss: 0.4262 — Accuracy: 0.8896\n",
      "Epoch  98/100 — Loss: 0.4255 — Accuracy: 0.8895\n",
      "Epoch  99/100 — Loss: 0.4402 — Accuracy: 0.8854\n",
      "Epoch 100/100 — Loss: 0.4341 — Accuracy: 0.8865\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)          # (batch, vocab_size)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * y_batch.size(0)\n",
    "        correct += (output.argmax(dim=1) == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch:3d}/{epochs} — Loss: {total_loss/total:.4f} — Accuracy: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f78ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(text, model, word_index, index_word, max_len, device):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize input the same way training data was tokenized\n",
    "    tokenized = [word_index[w] for w in tokenize(text) if w in word_index]\n",
    "\n",
    "    # Pre-pad to max_len - 1 (same shape as X during training)\n",
    "    padded = np.zeros((1, max_len - 1), dtype=np.int64)\n",
    "    padded[0, (max_len - 1 - len(tokenized)):] = tokenized\n",
    "\n",
    "    # Convert to tensor and send to GPU\n",
    "    input_tensor = torch.tensor(padded, dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)          # shape: (1, vocab_size)\n",
    "        predicted_idx = output.argmax(dim=1).item()\n",
    "\n",
    "    return index_word.get(predicted_idx, \"<unknown>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5f213e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is not a beauty during and down\n"
     ]
    }
   ],
   "source": [
    "def generate_text(seed_text, model, word_index, index_word, max_len, device, num_words=5):\n",
    "    result = seed_text\n",
    "    current_text = seed_text\n",
    "\n",
    "    for _ in range(num_words):\n",
    "        next_word = predict_next_word(current_text, model, word_index, index_word, max_len, device)\n",
    "        result += \" \" + next_word\n",
    "        current_text = result  # feed entire growing sentence back in\n",
    "\n",
    "    return result\n",
    "\n",
    "print(generate_text(\"He\", model, word_index, index_word, max_len, device, num_words=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68c8784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input     : 'He looks very'\n",
      "Next word : 'He looks very high before he really knew her the matter was so'\n"
     ]
    }
   ],
   "source": [
    "text = \"He looks very\"\n",
    "n = 10\n",
    "predicted_word = generate_text(text, model, word_index, index_word, max_len, device, num_words=n)\n",
    "print(f\"Input     : '{text}'\")\n",
    "print(f\"Next word : '{predicted_word}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Torch-GPU)",
   "language": "python",
   "name": "torch-gpu-projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
